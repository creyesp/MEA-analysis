{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing - Get features of flash response\n",
    "Classificate the light response in two group, transient and sustainded.   \n",
    "reference https://www.ncbi.nlm.nih.gov/pubmed/12966177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from spikelib import spiketools as spkt\n",
    "from spikelib.utils import check_directory, check_groups\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing - Flash features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'MR-0092'\n",
    "fspikes = '../data/sorting/MR-0092t2.result-1.hdf5'\n",
    "foutput = '../data/processed_protocols/MR-0092t2_modified_analysis_of_protocols_150um_merge.hdf5'\n",
    "fprotocol_times = '../data/sync/MR-0092t2/event_list_MR-0092t2.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read protocols times from sync file\n",
    "protocol_startwith = 'flash'\n",
    "filter_names = ['nd2', 'nd3', 'nd4', 'nd5']\n",
    "intensities = [50, 100, 150, 200, 255]\n",
    "\n",
    "nframes = 24\n",
    "protocol_times = pd.read_csv(fprotocol_times)\n",
    "filter_protocols = \\\n",
    "    protocol_times['protocol_name'].str.startswith(protocol_startwith)\n",
    "filter_frames = protocol_times['n_frames'] == nframes\n",
    "filter_flash = filter_protocols & filter_frames\n",
    "flash_time = protocol_times[filter_flash]\n",
    "\n",
    "# Temporal resolution\n",
    "psth_bin = 0.01  # In sec\n",
    "bandwidth_fit = psth_bin\n",
    "fit_resolution = 0.001  # In sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_flash_response(spks, panalysis, prefix, intensity,\n",
    "                       event_list, psth_bin, bandwidth_fit,\n",
    "                       fit_resolution, sr=20000.0, offset_time = 0.0):\n",
    "    \"\"\"Compute from spiketime psht and estimated FR.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    spks: h5py.Group\n",
    "    panalysis: h5py.Group\n",
    "    prefix: str\n",
    "    intensity: int\n",
    "    event_list: str\n",
    "    prefix: str\n",
    "    intensity: str\n",
    "    psth_bin: flaot\n",
    "    bandwidth_fit: float\n",
    "    fit_resolution: float\n",
    "    sr: float, defaul 20000.0\n",
    "    offset_time: float, default 0.0\n",
    "\n",
    "    \"\"\"\n",
    "    flash_name = 'flash_{}_{:d}'.format(prefix, intensity)\n",
    "    fiels_df = ['start_event', 'end_event', 'start_next_event']\n",
    "    filter_flash = (event_list['protocol_name'] == flash_name)\n",
    "    bound_time = np.array(event_list[filter_flash][fiels_df])/sr\n",
    "    # Stimulius time\n",
    "    (on_dur, off_dur) = np.median(np.diff(bound_time,axis=1), axis=0) # Seconds\n",
    "    start_on = offset_time\n",
    "    end_on = offset_time + on_dur\n",
    "    start_off = offset_time + on_dur\n",
    "    end_off = offset_time + off_dur + on_dur\n",
    "    total_dur = off_dur + on_dur\n",
    "    (start_trials, end_trials) = bound_time[:,[0,2]].T\n",
    "    ntrails = len(start_trials)\n",
    "    bins_fit = np.linspace(start_on, end_off,\n",
    "                            int(np.ceil(total_dur/fit_resolution))\n",
    "                           )\n",
    "    bins_psth = np.linspace(start_on, end_off,\n",
    "                            int(np.ceil(total_dur/psth_bin))\n",
    "                           )\n",
    "    # Name of group in HDF5 file\n",
    "    intensityg = '/flash/{}_{:03d}/'.format(prefix, intensity)\n",
    "    est_respg = '/flash/{}_{:03d}/est_psth/'.format(prefix, intensity)\n",
    "    psth_respg = '/flash/{}_{:03d}/psth/'.format(prefix, intensity)\n",
    "\n",
    "    check_groups(panalysis, [est_respg, psth_respg])\n",
    "    for key in spks['/spiketimes/']:\n",
    "        spikes = spks['/spiketimes/'+key][...]/sr\n",
    "        trials_flash = spkt.get_trials(spikes, start_trials, end_trials,\n",
    "                                        offset=offset_time)\n",
    "        spks_flash = spkt.flatten_trials(trials_flash)\n",
    "\n",
    "        # Response\n",
    "        (psth, _) = np.histogram(spks_flash, bins=bins_psth)\n",
    "        psth = psth/float(ntrails)\n",
    "        est_resp = spkt.est_pdf(trials_flash, bins_fit, bandwidth=bandwidth_fit,\n",
    "                                 norm_factor=psth.max())\n",
    "\n",
    "        if key in panalysis[est_respg]:\n",
    "            panalysis[est_respg+key][...] = est_resp\n",
    "        else:\n",
    "            panalysis[est_respg].create_dataset(key, data=est_resp, dtype=np.float, compression='gzip')\n",
    "\n",
    "        if key in panalysis[psth_respg]:\n",
    "            panalysis[psth_respg+key][...] = psth\n",
    "        else:\n",
    "            panalysis[psth_respg].create_dataset(key, data=psth, dtype=np.float, compression='gzip')\n",
    "\n",
    "    panalysis[intensityg].attrs['bounds'] = (start_on, end_on, start_off, end_off)\n",
    "    panalysis[psth_respg].attrs['bins'] = bins_psth\n",
    "    panalysis[est_respg].attrs['time'] = bins_fit\n",
    "    panalysis[est_respg].attrs['bounds'] = (start_on, end_on, start_off, end_off)\n",
    "    panalysis[est_respg].attrs['bounds_name'] = u'start_on,end_on,start_off,end_off'\n",
    "    \n",
    "    \n",
    "def get_flash_features(panalysis, prefix, intensity, kwargs_fit, kind='estimated'):\n",
    "    \"\"\"Compute a set of feature from estimated psth\n",
    "    \n",
    "    Parametes\n",
    "    ---------\n",
    "    panalysis: h5py.Group\n",
    "    prefix: str\n",
    "    intensity: int\n",
    "    kind: str\n",
    "        Source to get flash features\n",
    "    \"\"\"\n",
    "    est_respg = '/flash/{}_{:03d}/est_psth/'.format(prefix, intensity)\n",
    "    psth_respg = '/flash/{}_{:03d}/psth/'.format(prefix, intensity)\n",
    "    type_respg = '/flash/{}_{:03d}/type/'.format(prefix, intensity)\n",
    "    char_respg = '/flash/{}_{:03d}/char/'.format(prefix, intensity)\n",
    "\n",
    "    check_groups(panalysis, [est_respg, psth_respg, type_respg, char_respg])\n",
    "\n",
    "    for key in panalysis[est_respg]:\n",
    "        # TODO: add a if clause to select source from estimated or psth\n",
    "        est_resp = panalysis[est_respg + key]\n",
    "        est_time = panalysis[est_respg].attrs['time']\n",
    "        bounds = panalysis[est_respg].attrs['bounds']\n",
    "        type_fit, char_fit = spkt.get_features_flash(est_resp, est_time, bounds, **kwargs_fit)\n",
    "\n",
    "        if key in panalysis[char_respg]:\n",
    "            panalysis[char_respg+key][...] = char_fit\n",
    "        else:\n",
    "            panalysis[char_respg].create_dataset(key, data=char_fit, dtype=np.float, compression='gzip')\n",
    "\n",
    "        if key in panalysis[type_respg]:\n",
    "            panalysis[type_respg+key][...] = type_fit\n",
    "        else:\n",
    "            panalysis[type_respg].create_dataset(key, data=type_fit, dtype=np.int)        \n",
    "\n",
    "        col_name = u'latency_on,latency_off,bias_idx,decay_on,decay_off,\\\n",
    "                    resp_index_on,resp_index_off,sust_index_on,sust_index_off,\\\n",
    "                    peakresp_on,peakresp_off'\n",
    "        panalysis[char_respg].attrs['col_name'] = col_name\n",
    "        panalysis[type_respg].attrs['type_name'] = u'null:0,on:1,off:2,onoff:3'\n",
    "        panalysis[char_respg].attrs['kwargs'] = str(kwargs_fit)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get PSTH and estimated firing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in filter_names:\n",
    "    for intensity in intensities:\n",
    "        with h5py.File(fspikes, 'r') as spks,\\\n",
    "             h5py.File(foutput, 'a') as panalysis:\n",
    "            get_flash_response(\n",
    "                spks=spks,\n",
    "                panalysis=panalysis,\n",
    "                prefix=prefix,\n",
    "                intensity=intensity,\n",
    "                event_list=flash_time,\n",
    "                psth_bin=psth_bin,\n",
    "                bandwidth_fit=bandwidth_fit,\n",
    "                fit_resolution=fit_resolution,\n",
    "                sr=20000.0\n",
    "            )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute flash features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keywords for spkt.get_features_flash()\n",
    "fpeak_min_time = 0.01  # min time between peaks in sec\n",
    "kwargs_fit = {\n",
    "    'resp_thr': 1.0/3,  # Threshold to select valid unit based on number of trials\n",
    "    'bias_thr': 0.65,  # Threshold to classify into on, off, onoff\n",
    "    'ri_thr': 0.3,  # Threshold for Response Index (RI)\n",
    "    'ri_span': 0.1,  # Span for Response Index (RI)\n",
    "    'fpeak_thr': 0.5,  # threshold of max response to find the first peak of response\n",
    "    'fpeak_min_dist': int(fpeak_min_time/fit_resolution),\n",
    "    'sust_time': 0.4,  # Windows time to compute Sustained index in seg\n",
    "    'decrease_factor': np.e,\n",
    "}\n",
    "\n",
    "\n",
    "for prefix in filter_names:\n",
    "    for intensity in intensities:\n",
    "        with h5py.File(foutput, 'a') as panalysis:\n",
    "            get_flash_features(\n",
    "                panalysis=panalysis,\n",
    "                prefix=prefix,\n",
    "                intensity=intensity,\n",
    "                kwargs_fit=kwargs_fit\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:piptest]",
   "language": "python",
   "name": "conda-env-piptest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "794px",
    "left": "1478px",
    "right": "1px",
    "top": "127px",
    "width": "362px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
